# âœ‹ Sign Language Translation System

An AI-based system that detects and translates sign language gestures into text/speech using Computer Vision and hand-tracking techniques.

ğŸš€ This project was **independently designed and developed by me** from data processing to model implementation and testing.

---

## ğŸ“Œ Overview
This system uses a webcam to capture hand gestures, detects hand landmarks in real time, and translates the recognized signs into readable text or speech output.

The goal is to help bridge communication between sign language users and non-signers using AI technology.

---

## âœ¨ Features
- Real-time hand detection
- Hand landmark tracking
- Gesture classification
- Text output on screen
- Optional speech output
- Works with webcam

---

## ğŸ§  Technologies Used
- Python
- OpenCV
- MediaPipe (Hand Tracking)
- TensorFlow / Machine Learning
- NumPy
- Text-to-Speech libraries

---

## ğŸ—ï¸ My Role
This was a **solo project** where I:

- Designed the full system architecture
- Implemented hand tracking using MediaPipe
- Collected and prepared gesture data
- Trained the classification model
- Built the real-time prediction pipeline
- Integrated text/speech output
- Tested and optimized performance

---

## ğŸ“‚ Project Structure
